{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f25985c",
   "metadata": {},
   "source": [
    "# Classify snow-covered area (SCA) in Sentinel-2, Landsat 8/9, and PlanetScope imagery: full pipelines\n",
    "\n",
    "Rainey Aberle\n",
    "\n",
    "Department of Geosciences, Boise State University\n",
    "\n",
    "2022\n",
    "\n",
    "### Requirements:\n",
    "- Area of Interest (AOI) shapefile: used to query and crop imagery \n",
    "- Google Earth Engine (GEE) account: used to query imagery and the DEM (if no DEM is provided). Sign up for a free account [here](https://earthengine.google.com/new_signup/). \n",
    "- Digital elevation model (DEM; _optional_): used to extract elevations over the AOI and for each snowline. If no DEM is provided, the ArcticDEM Mosaic will be used where there is coverage; otherwise, the NASADEM will be used.\n",
    "- Pre-downloaded PlanetScope 4-band Surface Reflectance images (_optional_): download using the `Planet_images_order_download.ipynb` or through Planet Explorer. \n",
    "\n",
    "### Outline:\n",
    "__0. Setup__ paths in directory, file locations, authenticate GEE - _modify this section!_\n",
    "\n",
    "__1. Sentinel-2 Top of Atmosphere (TOA) imagery:__ full pipeline\n",
    "\n",
    "__2. Sentinel-2 Surface Reflectance (SR) imagery:__ full pipeline\n",
    "\n",
    "__3. Landsat 8/9 Surface Reflectance (SR) imagery:__ full pipeline\n",
    "\n",
    "__4. PlanetScope Surface Reflectance (SR) imagery:__ full pipeline\n",
    "\n",
    "-------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb21409d",
   "metadata": {},
   "source": [
    "### 0. Setup\n",
    "\n",
    "#### Define paths in directory and desired settings. \n",
    "Modify lines located within the following:\n",
    "\n",
    "`#### MODIFY HERE ####`  \n",
    "\n",
    "`#####################`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e40ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MODIFY HERE #####\n",
    "\n",
    "# -----Paths in directory\n",
    "# Name of study site used for output file names\n",
    "site_name = 'RGI60-01.00032'\n",
    "# path to folder containing AOI file\n",
    "aoi_path = '/Volumes/LaCie/raineyaberle/Research/PhD/snow_cover_mapping/study-sites/' + site_name + '/AOIs/'\n",
    "# AOI file name\n",
    "aoi_fn = site_name + '_outline.shp' \n",
    "# path to folder containing dem raster file\n",
    "dem_path = '/Volumes/LaCie/raineyaberle/Research/PhD/snow_cover_mapping/study-sites/' + site_name + '/DEMs/'\n",
    "# DEM file name\n",
    "# Note: set dem_fn=None if you want to use the ArcticDEM or NASADEM via Google Earth Engine\n",
    "dem_fn = None\n",
    "# path for output images\n",
    "out_path = aoi_path + '../imagery/'\n",
    "# path to PlanetScope images\n",
    "# Note: set ps_im_path=None if not using PlanetScope\n",
    "ps_im_path = out_path + 'PlanetScope/raw_images/'\n",
    "# path for output figures\n",
    "figures_out_path = aoi_path + '../figures/'\n",
    "\n",
    "# -----Define image search settings\n",
    "# Google Earth Engine project ID (default = \"ee-{YOUR USER NAME}\")\n",
    "project_id = 'ee-raineyaberle'\n",
    "# date ranges (inclusive)\n",
    "date_start = '2013-06-01'\n",
    "date_end = '2024-11-01'\n",
    "month_start = 6\n",
    "month_end = 10\n",
    "# whether to mask clouds in images\n",
    "mask_clouds = True \n",
    "# minimum portion of AOI covered after cloud filtering\n",
    "min_aoi_coverage = 70\n",
    "\n",
    "# -----Determine image download, clipping & plotting settings\n",
    "# Note: if im_download = False, but images over the aoi exceed GEE limit, images must be downloaded regardless.\n",
    "im_download = False  # = True to download all satellite images by default\n",
    "delineate_snowline = False # = True to delineate the snowline in classified images\n",
    "plot_results = True # = True to plot figures of results for each image where applicable\n",
    "save_outputs = True # = True to save SCAs and snowlines to file\n",
    "verbose = True # = True to print details for each image during each step\n",
    "skip_clipped = False # = True to skip PlanetScope images where bands appear \"clipped\", i.e. max(blue) < 0.8\n",
    "\n",
    "#######################\n",
    "\n",
    "# -----Import packages\n",
    "import xarray as xr\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from matplotlib import pyplot as plt, dates\n",
    "import matplotlib\n",
    "import rasterio as rio\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import sys\n",
    "import ee\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import dump, load\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -----Make output directory if it doesn't exist\n",
    "if not os.path.exists(out_path):\n",
    "    os.mkdir(out_path)\n",
    "    print('Made directory for outputs: ', out_path)\n",
    "\n",
    "# -----Set paths for output files\n",
    "s2_toa_im_path = os.path.join(out_path, 'Sentinel-2_TOA')\n",
    "s2_sr_im_path = os.path.join(out_path, 'Sentinel-2_SR')\n",
    "l_im_path = os.path.join(out_path, 'Landsat')\n",
    "ps_im_masked_path = os.path.join(out_path, 'PlanetScope', 'masked')\n",
    "ps_im_mosaics_path = os.path.join(out_path, 'PlanetScope', 'mosaics')\n",
    "im_classified_path = os.path.join(out_path, 'classified')\n",
    "snow_cover_stats_path = os.path.join(out_path, 'snow_cover_stats')\n",
    "\n",
    "# -----Import pipeline utilities\n",
    "# When running locally, must import from \"functions\" folder\n",
    "script_path = os.getcwd()\n",
    "if \"functions\" in os.listdir(os.path.join(script_path, '..')):\n",
    "    sys.path.append(os.path.join(script_path, '..', 'functions'))\n",
    "# In Docker image, all files are in \"/app\" folder\n",
    "else:\n",
    "    sys.path.append(os.path.join(script_path))\n",
    "import pipeline_utils_SKL as utils\n",
    "import PlanetScope_preprocessing as psp\n",
    "\n",
    "# -----Load dataset dictionary\n",
    "dataset_dict_fn = os.path.join(script_path, '..', 'inputs-outputs', 'datasets_characteristics.json')\n",
    "dataset_dict = json.load(open(dataset_dict_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11868768",
   "metadata": {},
   "source": [
    "#### Authenticate and initialize Google Earth Engine (GEE). \n",
    "\n",
    "__Note:__ The first time you run the following cell, you will be asked to authenticate your GEE account for use in this notebook. This will send you to an external web page, where you will walk through the GEE authentication workflow and copy an authentication code back into the space below this cell when prompted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ab8458",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ee.Initialize(project=project_id)\n",
    "except: \n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f2591c",
   "metadata": {},
   "source": [
    "#### Load AOI and DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91150c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Load AOI as gpd.GeoDataFrame\n",
    "aoi = gpd.read_file(os.path.join(aoi_path, aoi_fn))\n",
    "# reproject the AOI to WGS84 to solve for the optimal utm zone\n",
    "aoi_wgs = aoi.to_crs('EPSG:4326')\n",
    "aoi_wgs_centroid = [aoi_wgs.geometry[0].centroid.xy[0][0],\n",
    "                    aoi_wgs.geometry[0].centroid.xy[1][0]]\n",
    "# grab the optimal UTM zone EPSG code\n",
    "epsg_utm = utils.convert_wgs_to_utm(aoi_wgs_centroid[0], aoi_wgs_centroid[1])\n",
    "print('Optimal UTM CRS = EPSG:' + str(epsg_utm))\n",
    "# reproject AOI to the optimal UTM zone\n",
    "aoi_utm = aoi.to_crs(f'EPSG:{epsg_utm}')\n",
    "\n",
    "# -----Load DEM as Xarray DataSet\n",
    "if dem_fn is None:\n",
    "    # query GEE for DEM\n",
    "    dem = utils.query_gee_for_dem(aoi_utm, site_name, dem_path)\n",
    "else:\n",
    "    # load DEM as xarray DataSet\n",
    "    dem = xr.open_dataset(os.path.join(dem_path, dem_fn))\n",
    "    dem_crs = str(dem.rio.crs.to_epsg())\n",
    "    dem = utils.adjust_dem_data_vars(dem)\n",
    "    # set no data values to NaN\n",
    "    dem = xr.where((dem > 1e38) | (dem <= -9999), np.nan, dem)\n",
    "    # reproject the DEM to the optimal utm zone\n",
    "    dem = dem.rio.write_crs(f'EPSG:{dem_crs}')\n",
    "    if dem_crs is not epsg_utm:\n",
    "        dem = dem.rio.reproject(f'EPSG:{epsg_utm}')\n",
    "\n",
    "# -----Plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "dem_im = ax.imshow(dem.elevation.data, cmap='terrain', \n",
    "          extent=(np.min(dem.x.data)/1e3, np.max(dem.x.data)/1e3, np.min(dem.y.data)/1e3, np.max(dem.y.data)/1e3))\n",
    "if type(aoi_utm.geometry[0])==Polygon:\n",
    "    ax.plot([x/1e3 for x in aoi_utm.geometry[0].exterior.coords.xy[0]],\n",
    "            [y/1e3 for y in aoi_utm.geometry[0].exterior.coords.xy[1]], '-k')\n",
    "elif type(aoi_utm.geometry[0])==MultiPolygon:\n",
    "    [ax.plot([x/1e3 for x in geom.exterior.coords.xy[0]],\n",
    "            [y/1e3 for y in geom.exterior.coords.xy[1]], '-k') for geom in aoi_utm.geometry[0].geoms]\n",
    "ax.grid()\n",
    "ax.set_xlabel('Easting [km]')\n",
    "ax.set_ylabel('Northing [km]')\n",
    "fig.colorbar(dem_im, ax=ax, shrink=0.5, label='Elevation [m.a.s.l.]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269491c1",
   "metadata": {},
   "source": [
    "## 1. Sentinel-2 TOA imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b4e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849520de",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Query GEE for imagery and run classification pipeline\n",
    "# Define dataset\n",
    "dataset = 'Sentinel-2_TOA'\n",
    "# Load trained image classifier\n",
    "clf_fn = os.path.join(script_path, '..', 'inputs-outputs', 'Sentinel-2_TOA_classifier_all_sites.joblib')\n",
    "clf = load(clf_fn)\n",
    "# Load feature columns (bands to use in classification)\n",
    "feature_cols_fn = os.path.join(script_path, '..', 'inputs-outputs', 'Sentinel-2_TOA_feature_columns.json')\n",
    "feature_cols = json.load(open(feature_cols_fn))\n",
    "# Run the classification pipeline\n",
    "run_pipeline=True\n",
    "utils.query_gee_for_imagery_yearly(aoi_utm, dataset, date_start, date_end, month_start, month_end, mask_clouds, min_aoi_coverage,\n",
    "                                im_download, s2_toa_im_path, run_pipeline, dataset_dict, site_name, im_classified_path,\n",
    "                                snow_cover_stats_path, dem, clf, feature_cols, figures_out_path, plot_results, verbose, delineate_snowline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a9a5e7",
   "metadata": {},
   "source": [
    "## 2. Sentinel-2 SR imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66209569",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Query GEE for imagery and run classification pipeline\n",
    "# Define dataset\n",
    "dataset = 'Sentinel-2_SR'\n",
    "# Load trained image classifier\n",
    "clf_fn = os.path.join(script_path, '..', 'inputs-outputs', 'Sentinel-2_SR_classifier_all_sites.joblib')\n",
    "clf = load(clf_fn)\n",
    "# Load feature columns (bands to use in classification)\n",
    "feature_cols_fn = os.path.join(script_path, '..', 'inputs-outputs', 'Sentinel-2_SR_feature_columns.json')\n",
    "feature_cols = json.load(open(feature_cols_fn))\n",
    "# Run the classification pipeline\n",
    "run_pipeline=True\n",
    "utils.query_gee_for_imagery_yearly(aoi_utm, dataset, date_start, date_end, month_start, month_end, mask_clouds, min_aoi_coverage,\n",
    "                                im_download, s2_sr_im_path, run_pipeline, dataset_dict, site_name, im_classified_path,\n",
    "                                snow_cover_stats_path, dem, clf, feature_cols, figures_out_path, plot_results, verbose, delineate_snowline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fce51d",
   "metadata": {},
   "source": [
    "## 3. Landsat 8/9 SR imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d99e5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Query GEE for imagery (and download to l_im_path if necessary)\n",
    "# Define dataset\n",
    "dataset = 'Landsat'\n",
    "# Load trained image classifier\n",
    "clf_fn = os.path.join(script_path, '..', 'inputs-outputs', 'Landsat_classifier_all_sites.joblib')\n",
    "clf = load(clf_fn)\n",
    "# Load feature columns (bands to use in classification)\n",
    "feature_cols_fn = os.path.join(script_path, '..', 'inputs-outputs', 'Landsat_feature_columns.json')\n",
    "feature_cols = json.load(open(feature_cols_fn))\n",
    "# Run the classification pipeline\n",
    "run_pipeline=True\n",
    "im_download=True\n",
    "start_date = '2014-05-01'\n",
    "end_date = '2014-06-01'\n",
    "utils.query_gee_for_imagery_yearly(aoi_utm, dataset, date_start, date_end, month_start, month_end, mask_clouds, min_aoi_coverage,\n",
    "                                im_download, l_im_path, run_pipeline, dataset_dict, site_name, im_classified_path,\n",
    "                                snow_cover_stats_path, dem, clf, feature_cols, figures_out_path, plot_results, verbose, delineate_snowline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2048e3ee",
   "metadata": {},
   "source": [
    "## 4. PlanetScope SR imagery\n",
    "\n",
    "### Pre-process raw imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b96e06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Read surface reflectance image file names\n",
    "os.chdir(ps_im_path)\n",
    "im_fns = sorted(glob.glob('*SR*.tif'))\n",
    "\n",
    "# ----Mask clouds and cloud shadows in all images\n",
    "plot_results = False\n",
    "if mask_clouds:\n",
    "    print('Masking images using cloud bitmask...')\n",
    "    for im_fn in tqdm(im_fns):\n",
    "        psp.planetscope_mask_image_pixels(ps_im_path, im_fn, ps_im_masked_path, save_outputs, plot_results)\n",
    "# read masked image file names\n",
    "os.chdir(ps_im_masked_path)\n",
    "im_masked_fns = sorted(glob.glob('*_mask.tif'))\n",
    "\n",
    "# -----Mosaic images captured within same hour\n",
    "print('Mosaicking images captured in the same hour...')\n",
    "if mask_clouds:\n",
    "    psp.planetscope_mosaic_images_by_date(ps_im_masked_path, im_masked_fns, ps_im_mosaics_path, aoi_utm)\n",
    "    print(' ')\n",
    "else:\n",
    "    psp.planetscope_mosaic_images_by_date(ps_im_path, im_fns, ps_im_mosaics_path, aoi_utm)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4f5b38",
   "metadata": {},
   "source": [
    "### Run snow detection workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeeff3c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Load trained classifier and feature columns\n",
    "clf_fn = os.path.join(script_path, '..', 'inputs-outputs', 'PlanetScope_classifier_all_sites.joblib')\n",
    "clf = load(clf_fn)\n",
    "feature_cols_fn = os.path.join(script_path, '..', 'inputs-outputs', 'PlanetScope_feature_columns.json')\n",
    "feature_cols = json.load(open(feature_cols_fn))\n",
    "dataset = 'PlanetScope'\n",
    "\n",
    "# -----Iterate over image mosaics\n",
    "# read image mosaic file names\n",
    "os.chdir(ps_im_mosaics_path)\n",
    "im_mosaic_fns = sorted(glob.glob('*.tif'))\n",
    "# create polygon(s) of the top and bottom 20th percentile elevations within the AOI\n",
    "polygons_top, polygons_bottom = psp.create_aoi_elev_polys(aoi_utm, dem)\n",
    "# loop through images\n",
    "for im_mosaic_fn in tqdm(im_mosaic_fns):\n",
    "\n",
    "    # -----Determine image date from image mosaic file name\n",
    "    im_date = im_mosaic_fn[0:4] + '-' + im_mosaic_fn[4:6] + '-' + im_mosaic_fn[6:8] + 'T' + im_mosaic_fn[9:11] + ':00:00'\n",
    "    im_dt = np.datetime64(im_date)\n",
    "    if verbose:\n",
    "        print(im_date)\n",
    "\n",
    "    # -----Open image mosaic\n",
    "    im_da = xr.open_dataset(os.path.join(ps_im_mosaics_path, im_mosaic_fn))\n",
    "\n",
    "    # -----Adjust radiometry\n",
    "    im_adj, im_adj_method = psp.planetscope_adjust_image_radiometry(im_da, im_dt, polygons_top, polygons_bottom,\n",
    "                                                                    dataset_dict, skip_clipped)\n",
    "    if type(im_adj) is str:  # skip if there was an error in adjustment\n",
    "        continue    \n",
    "    \n",
    "    # -----Check if classified image already exists in file\n",
    "    # check if classified image already exists in file\n",
    "    im_classified_fn = im_date.replace('-', '').replace(':',\n",
    "                                                        '') + '_' + site_name + '_' + dataset + '_classified.nc'\n",
    "    if os.path.exists(os.path.join(im_classified_path, im_classified_fn)):\n",
    "        if verbose:\n",
    "            print('Classified image already exists in file, loading...')\n",
    "        im_classified = xr.open_dataset(os.path.join(im_classified_path, im_classified_fn))\n",
    "        \n",
    "        # remove no data values\n",
    "        im_classified = xr.where(im_classified == -9999, np.nan, im_classified)\n",
    "        # reproject to UTM\n",
    "        im_classified = im_classified.rio.write_crs('EPSG:4326')\n",
    "        im_classified = im_classified.rio.reproject('EPSG:' + epsg_utm)\n",
    "    else:\n",
    "\n",
    "        # -----Check that image mosaic covers at least min_aoi_coverage of the AOI\n",
    "        # Create dummy band for AOI masking comparison\n",
    "        im_adj['aoi_mask'] = (['time', 'y', 'x'], np.ones(np.shape(im_adj[dataset_dict[dataset]['RGB_bands'][0]].data)))\n",
    "        im_aoi = im_adj.rio.clip(aoi_utm.geometry, im_adj.rio.crs)\n",
    "        # Calculate the percentage of real values in the AOI    \n",
    "        perc_real_values_aoi = (len(np.where(~np.isnan(np.ravel(im_aoi[dataset_dict[dataset]['RGB_bands'][0]].data)))[0])\n",
    "                                / len(np.where(~np.isnan(np.ravel(im_aoi['aoi_mask'].data)))[0]))\n",
    "        if perc_real_values_aoi < min_aoi_coverage:\n",
    "            if verbose:\n",
    "                print(f'Less than {min_aoi_coverage}% coverage of the AOI, skipping image...')\n",
    "                print(' ')\n",
    "            continue\n",
    "\n",
    "        # -----Classify image\n",
    "        im_classified = utils.classify_image(im_adj, clf, feature_cols, aoi_utm, dataset_dict,\n",
    "                                         dataset, im_classified_fn, im_classified_path, verbose)\n",
    "        if type(im_classified) == str:\n",
    "            continue\n",
    "\n",
    "    # -----Calculate snow cover stats\n",
    "    # check if snow cover stats already exists in file\n",
    "    scs_fn = im_date.replace('-', '').replace(':', '') + '_' + site_name + '_' + dataset + '_snowline.csv'\n",
    "    if os.path.exists(os.path.join(snow_cover_stats_path, scs_fn)):\n",
    "        if verbose:\n",
    "            print('Snowline already exists in file, skipping...')\n",
    "            print(' ')\n",
    "        continue    \n",
    "    else:\n",
    "        plot_results = True\n",
    "        scs_df = utils.calculate_snow_cover_stats(dataset_dict, dataset, im_date, im_classified, dem, aoi_utm, site_name, delineate_snowline, \n",
    "                                                       scs_fn, snow_cover_stats_path, figures_out_path, plot_results, verbose)\n",
    "        plt.close()\n",
    "        if verbose:\n",
    "            print('Transient Accumulation Area Ratio =  ' + str(scs_df['transient_AAR'][0]))\n",
    "    if verbose:\n",
    "        print(' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gscm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
