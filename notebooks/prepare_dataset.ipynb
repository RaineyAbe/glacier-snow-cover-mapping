{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a32290-0faf-49be-9c69-6c5920f68555",
   "metadata": {},
   "source": [
    "# Prepare dataset for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5011ea6-27fa-49a2-8b80-bcc2fbca178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import os\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c885f99-be9e-421d-b6a8-c313e49b0ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to \"glacier-snow-cover-mapping\" and path to data\n",
    "base_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping/'\n",
    "data_path = '/Volumes/LaCie/raineyaberle/Research/PhD/write-ups/CH1_snow_cover_mapping_methods_manuscript/Aberle_et_al_dataset_submission/'\n",
    "\n",
    "# Load functions\n",
    "sys.path.insert(1, os.path.join(base_path, 'functions'))\n",
    "import pipeline_utils as f\n",
    "\n",
    "# Grab site names from data_path\n",
    "site_names = [site_name for site_name in sorted(os.listdir(data_path)) \n",
    "              if os.path.isdir(os.path.join(data_path, site_name))]\n",
    "site_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b693c48-38cd-48ef-a5ac-864fced7b837",
   "metadata": {},
   "source": [
    "## Snow cover statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91398898-a9cf-4610-b4e7-723a81f843c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define snow cover stats columns\n",
    "scs_cols = ['site_name', 'datetime', 'source', 'HorizontalCRS', 'VerticalCRS', \n",
    "            'SCA_m2', 'AAR', 'ELA_from_AAR_m', 'snowline_elevs_m', 'snowline_elevs_median_m',  \n",
    "            'snowlines_coords_X', 'snowlines_coords_Y', 'snowline_geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235fe209-b307-4d1b-a355-4bdd090269af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate over site names\n",
    "for site_name in site_names:\n",
    "    print(f'\\n{site_name}')\n",
    "    \n",
    "    # Load snow cover stats CSV\n",
    "    scs_fn = glob.glob(os.path.join(data_path, site_name, f'{site_name}_snow_cover_stats.csv'))[0]\n",
    "    scs_df = pd.read_csv(scs_fn)\n",
    "    scs_df['datetime'] = pd.to_datetime(scs_df['datetime'])\n",
    "    \n",
    "    # Rename \"geometry\" column\n",
    "    if 'geometry' in list(scs_df.columns):\n",
    "        scs_df.rename(columns={'geometry': 'snowline_geometry'}, inplace=True)\n",
    "    # Rename \"dataset\" column\n",
    "    if 'dataset' in list(scs_df.columns):\n",
    "        scs_df.rename(columns={'dataset': 'source'}, inplace=True)\n",
    "        \n",
    "    # Re-assign Vertical CRS column from \"EGM95 geoid (EPSG:5773)\" to \"EPSG:5773\"\n",
    "    scs_df['VerticalCRS'] = 'EPSG:5773'\n",
    "    \n",
    "    # Make sure dataframe is ordered by datetime\n",
    "    scs_df.sort_values(by='datetime', inplace=True)\n",
    "    \n",
    "    # Re-order columns\n",
    "    scs_df = scs_df[scs_cols]\n",
    "\n",
    "    # Re-save to file\n",
    "    scs_df.to_csv(scs_fn, index=False)\n",
    "    print('Snow cover stats re-saved to file:', scs_fn)\n",
    "    \n",
    "scs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3605d5fd-9810-4d83-923e-5ee522c6011a",
   "metadata": {},
   "source": [
    "## Classified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79294ffc-000e-4325-80d2-4b1b010d0d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define attributes for image files\n",
    "attrs = {'Description': 'Classified image',\n",
    "         'Classes' : '1 = Snow, 2 = Shadowed snow, 4 = Ice, 5 = Rock, 6 = Water',\n",
    "         '_FillValue' : -9999}\n",
    "attrs_order = ['Description', 'Classes', 'datetime', 'source', '_FillValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bdb77c-14e3-42a9-918c-c37695fc4a35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for site_name in site_names:\n",
    "    print(f'\\n{site_name}')\n",
    "    \n",
    "    # Grab all classified image names\n",
    "    im_classified_fns = sorted(glob.glob(os.path.join(data_path, site_name, 'classified-images', '*.nc')))\n",
    "\n",
    "    # Iterate over image file names\n",
    "    for im_classified_fn in tqdm(im_classified_fns):\n",
    "        # Open image file\n",
    "        im_classified = xr.open_dataset(im_classified_fn)\n",
    "        \n",
    "        # Set \"0\" values to -9999\n",
    "        im_classified = xr.where(im_classified.classified==0, -9999, im_classified)\n",
    "        \n",
    "        # Grab datetime and dataset from file name\n",
    "        datetime = os.path.basename(im_classified_fn).split('_')[0]\n",
    "        dataset = os.path.basename(im_classified_fn).split('_')[2]\n",
    "        \n",
    "        # Set attributes\n",
    "        attrs_image = attrs\n",
    "        attrs_image['datetime'] = datetime\n",
    "        attrs_image['source'] = dataset\n",
    "        attrs_image = {k: attrs_image[k] for k in attrs_order}\n",
    "        im_classified = im_classified.assign_attrs(attrs_image)\n",
    "        \n",
    "        # Reproject image to UTM if necessary\n",
    "        if im_classified.x.data[0] < 0:\n",
    "            im_classified = im_classified.rio.write_crs('EPSG:4326')\n",
    "            # Reproject to UTM\n",
    "            epsg_utm = f.convert_wgs_to_utm(im_classified.x.data[0], im_classified.y.data[0])\n",
    "            im_classified = im_classified.rio.reproject(f'EPSG:{epsg_utm}', nodata=-9999)\n",
    "            \n",
    "        # Plot\n",
    "        # plt.figure()\n",
    "        # plt.imshow(im_classified.classified.data[0], \n",
    "        #   extent=(np.min(im_classified.x.data), np.max(im_classified.x.data),\n",
    "        #          np.min(im_classified.y.data), np.max(im_classified.y.data)))\n",
    "        # plt.colorbar(shrink=0.5)\n",
    "        # plt.show()\n",
    "\n",
    "        # Re-save to file\n",
    "        im_classified.to_netcdf(im_classified_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8060713e-6d28-4bd9-942a-37399416d1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow-cover-mapping",
   "language": "python",
   "name": "snow-cover-mapping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
